# 1. Import the libraries for classification to include pipeline
from pyspark.sql.types import *
from pyspark.sql.functions import *

from pyspark.ml import import Pipeline
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import VectorAssembler



# 2. Load the flight dataset
csv = spark.read.csv('wasb:///data/flights.csv', inferSchema=True, header=True )

# 3. Prepare Data
data = csv.select("DayofMonth","DayOfWeek", "Carrier", "OriginAirportID", "DestAirportID","DepDelay",((col("ArrDelay")>15).cast("Double").alias("label")))


# 4. Split the data
splits = data.randomSplit([0.7, 0.3])
train = splits[0]
test = splits[1].withColumnRenamed("label", "trueLabel")


# 5. Define the pipeline
assembler = VectorAssembler( inputCols = ["DayofMonth","DayOfWeek", "OriginAirportID", "DestAirportID","DepDelay"], outputCol="features")
lr = LinearRegression( labelCol="label", featuresCol="features", maxIter=10, regParam=0.3)
pipeline = Pipeline( stages=[assembler, lr] )

# 6. Train model
pipelineModel = pipeline.fit( train )


# 7. Test teh model
prediction = pipelineModel.transform( test )
predicted = prediction.select("features", "prediction", "trueLabel" )
predicted.show(100, truncate=False)


# 8. Compute Confusion Matrix Metrics
tp = float( predicted.filter("prediction == 1.0 AND truelabel == 1").count())
fp = float( predicted.filter("prediction == 1.0 AND truelabel == 0").count())
tn = float( predicted.filter("prediction == 0.0 AND truelabel == 0").count())
fn = float( predicted.filter("prediction == 0.0 AND truelabel == 1").count())
metrics = spark.createDataFrame([
   ("TP", tp),
   ("FP", fp),
   ("TN", tn),
   ("FN", fn),
   ("Precision", tp/(tp + fp)),
    "Recall", tp/(tp + fn)], ["metric", "value"])
metrics.show()



# 9. Raw Prediction and Probability
prediction.select("rawPrediction", "probability", "prediction". "trueLabel").show(100, truncate=False)


# 10. Review ROC and AUC

from pyspark.ml.evaluation import BinaryClassificationEvaluator

evaluator = BinaryClassificationEvaluator( labelCol="trueLabel", rawPredictionCol="rawPrediction")
auc = evaluator.evaluate( prediction ) 
print "AUC = ", auc


# 11. Change threshold and retest the pipeline
lr2 = LinearRegression( labelCol="label", featuresCol="features", threshold=0.35, maxIter=10, regParam=0.3)
pipeline2 = Pipeline( stages=[assembler, lr2] )

# Retrain model
pipelineModel2 = pipeline2.fit( train )


# Retest themodel
newPrediction = pipelineModel2.transform( test )
newPrediction.select("rawPrediction", "probability",  "prediction", "trueLabel" )



# 12. Recompute Confusion Matrix Metrics
tp2 = float( newPrediction.filter("prediction == 1.0 AND truelabel == 1").count())
fp2 = float( newPrediction.filter("prediction == 1.0 AND truelabel == 0").count())
tn2 = float( newPrediction.filter("prediction == 0.0 AND truelabel == 0").count())
fn2 = float( newPrediction.filter("prediction == 0.0 AND truelabel == 1").count())
metrics2 = spark.createDataFrame([
   ("TP", tp),
   ("FP", fp),
   ("TN", tn),
   ("FN", fn),
   ("Precision", tp/(tp + fp)),
    "Recall", tp/(tp + fn)], ["metric", "value"])
metrics2.show()