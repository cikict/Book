# 1. Import the libraries for classification to include pipeline
from pyspark.sql.types import *
from pyspark.sql.functions import *

from pyspark.ml import import Pipeline
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit
from pyspark.ml.evaluation import BinaryClassificationEvaluator


# 2. Load the flight dataset
csv = spark.read.csv('wasb:///data/flights.csv', inferSchema=True, header=True )


# 3. Prepare Data
data = csv.select("DayofMonth","DayOfWeek", "Carrier", "OriginAirportID", "DestAirportID","DepDelay",((col("ArrDelay")>15).cast("Double").alias("label")))


# 4. Split the data
splits = data.randomSplit([0.7, 0.3])
train = splits[0]
test = splits[1].withColumnRenamed("label", "trueLabel")


# 5. Define the pipeline
assembler = VectorAssembler( inputCols = ["DayofMonth","DayOfWeek", "OriginAirportID", "DestAirportID","DepDelay"], outputCol="features")
lr = LogisticRegression( labelCol="label", featuresCol="features") # Use default parameters
pipeline = Pipeline( stages=[assembler, lr] )


#6. Tune Parameters
ParamGridBuilder().addGrid( lr.regParams, [0.3, 0.01]).addGrid(lr.maxIter, [10, 5].addGrid(lr.threshold, [0.35, 0.30]).build()
tvs - TrainValidationSplit( estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)
model = tvs.fit( train) 


#7 Test the model
prediction = model.transform( test)
predicted = prediction.select( "prediction", "probability". "trueLable")
predicted.show(100, truncate=False)





